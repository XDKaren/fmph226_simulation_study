---
title: "FMPH243A simulation3"
author: "Keren Hu, Jennifer Zhang"
date: "2023-11-16"
output: pdf_document
---

## Model performance

### 1. Poisson log-linear regression model

```{r, message=FALSE}
library(MASS)
set.seed(2023)

M <- 1000  
n <- 1000   
beta0 <- 1
beta1 <- 1
sigma_sq_x <- 1
sigma_sq_b <- 2

beta0_1 <- log(3) + 0.5*sigma_sq_b + beta0


# Initialize vectors
beta_hats <- matrix(0, ncol = 2, nrow = M)
asy_var <- list()
Tws <- numeric(M)

for (m in 1:M) {
  # Simulate data for each iteration
  # Simulating random effects bi
  bi <- rnorm(n, mean = 0, sd = sqrt(sigma_sq_b))
  
  # Simulating predictor variable xi
  xi <- rnorm(n, mean = 1, sd = sqrt(sigma_sq_x))
  
  # Simulating correlated count responses u_it
  u <- matrix(0, nrow = n, ncol = 3)
  for (i in 1:n) {
    mu_it <- exp(beta0 + xi[i] * beta1 + bi[i])
    for (t in 1:3){
      u[i, t] <- rpois(1, mu_it)
    }
  }
  y <- rowSums(u)
  
  # Fit Poisson log-linear regression model
  m1 <- glm(y ~ xi, family = poisson(link = "log"))
  
  # Obtain estimates and associated asymptotic variance
  beta_hats[m,] <- t(as.matrix(coef(m1)))
  var_hat <- diag(vcov(m1))[2]
  
  # Compute Wald statistic for testing the null hypothesis beta1 = 1
  Tw <- (beta_hats[m,2] - beta1)^2 / var_hat
  
  # Store results for each iteration
  asy_var[[m]] <- vcov(m1)
  Tws[m] <- Tw
}

# Compute empirical type I error rate
## compare to alpha = 0.05
mean(Tws >= qchisq(0.95, df = 1))

# Compute MC estimate of beta
## compare to true value (3.098612, 1)
colMeans(beta_hats)

# Compute MC estimate of associated asymptotic variances
Reduce("+", asy_var)/M
# Compute MC estimate of empirical variances
var(beta_hats)
```

### 2. NB log-linear regression model

```{r, warning=FALSE}
library(MASS)
set.seed(2023)

M <- 1000  
n <- 1000   
beta0 <- 1
beta1 <- 1
sigma_sq_x <- 1
sigma_sq_b <- 2


# Initialize vectors to store results
beta_hats <- matrix(0, ncol = 2, nrow = M)
asy_var <- list()
Tws <- numeric(M)

errors <- list()
error_data <- list()

for (m in 1:M) {
  # Using tryCatch to catch errors
  tryCatch({
    # Simulate data for each iteration
    # Simulating random effects bi
    bi <- rnorm(n, mean = 0, sd = sqrt(sigma_sq_b))
  
    # Simulating predictor variable xi
    xi <- rnorm(n, mean = 1, sd = sqrt(sigma_sq_x))
  
    # Simulating correlated count responses u_it
    u <- matrix(0, nrow = n, ncol = 3)
    for (i in 1:n) {
      mu_it <- exp(beta0 + xi[i] * beta1 + bi[i])
      for (t in 1:3){
        u[i, t] <- rpois(1, mu_it)
      }
    }
    y <- rowSums(u)
  
    # Fit NB log-linear regression model
    m2 <- glm.nb(y ~ xi)
  
    # Obtain estimates and associated asymptotic variance
    beta_hats[m,] <- t(as.matrix(coef(m2)))
    var_hat <- diag(vcov(m2))[2]
  
    # Compute Wald statistic for testing the null hypothesis beta1 = 1
    Tw <- (beta_hats[m,2] - beta1)^2 / var_hat
  
    # Store results for each iteration
    asy_var[[m]] <- vcov(m2)
    Tws[m] <- Tw
  }, error = function(e) {
    # Store error message
    errors[[m]] <- conditionMessage(e)
    # Store dataset causing the error
    error_data[[m]] <- list(bi = bi, xi = xi, u = u, y = y)
  })
}

# Compute empirical type I error rate
## compare to alpha = 0.05
mean(Tws >= qchisq(0.95, df = 1))

# Compute MC estimate of beta
## compare to true value (3.098612, 1)
colMeans(beta_hats)

# Compute MC estimate of associated asymptotic variances
asy_array <- array(unlist(asy_var), dim = c(2, 2, length(asy_var)))
apply(asy_array, c(1, 2), mean)

# Compute MC estimate of empirical variances
var(beta_hats)
```

### 3. Semiparametric log-linear model with the working variance

```{r, warning=FALSE, results='hide', message=FALSE}
library(MASS)
library(geepack)
library(gee)
set.seed(2023)

M <- 1000  
n <- 2000   
beta0 <- 1
beta1 <- 1
sigma_sq_x <- 1
sigma_sq_b <- 2

beta0_1 <- log(3) + 0.5*sigma_sq_b + beta0


# Initialize vectors to store results
beta_hats <- matrix(0, ncol = 2, nrow = M)
asy_var <- list()
Tws <- numeric(M)

for (m in 1:M) {
  # Simulate data for each iteration
  # Simulating random effects bi
  bi <- rnorm(n, mean = 0, sd = sqrt(sigma_sq_b))
  
  # Simulating predictor variable xi
  xi <- rnorm(n, mean = 1, sd = sqrt(sigma_sq_x))
  
  # Simulating correlated count responses u_it
  u <- matrix(0, nrow = n, ncol = 3)
  for (i in 1:n) {
    mu_it <- exp(beta0 + xi[i] * beta1 + bi[i])
    for (t in 1:3){
      u[i, t] <- rpois(1, mu_it)
    }
  }
  y <- rowSums(u)
  
  # Create a data frame for GEE modeling
  df <- data.frame(y = y, xi = xi, id = seq(1,n))
  
  # Fit GEE regression model
  m3 <- gee(y ~ xi, data = df, family = "poisson")
  
  # Obtain estimates and associated asymptotic variance
  beta_hats[m,] <- m3$coefficients
  var_hat <-m3$robust.variance["xi", "xi"]
  
  # Compute Wald statistic for testing the null hypothesis beta1 = 1
  Tw <- (beta_hats[m, 2] - beta1)^2 / var_hat
  
  # Store results for each iteration
  asy_var[[m]] <- m3$robust.variance
  Tws[m] <- Tw
}
```
```{r}
# Compute empirical type I error rate
## compare to alpha = 0.05
mean(Tws >= qchisq(0.95, df = 1))

# Compute MC estimate of beta
## compare to true value (, 1)
colMeans(beta_hats)

# Compute MC estimate of associated asymptotic variances
Reduce("+", asy_var)/M
# Compute MC estimate of empirical variances
var(beta_hats)
```

